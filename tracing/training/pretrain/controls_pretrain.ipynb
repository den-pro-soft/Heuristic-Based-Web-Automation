{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracing.rl.a3cmodel import A3CModel\n",
    "from tracing.rl.actions import *\n",
    "from tracing.selenium_utils.controls import Types\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import threading\n",
    "import json\n",
    "import random\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '../../../resources/controls_popups_dataset.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(arr, batch_size):\n",
    "    batch = []\n",
    "    for item in arr:\n",
    "        if len(batch) >= batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "\n",
    "        batch.append(item)\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        yield batch\n",
    "        \n",
    "        \n",
    "def read_img(ctrl, size = 300):\n",
    "    img = misc.imread(ctrl['img_file'])\n",
    "    img = (img - 128.)/128.\n",
    "    shape = img.shape\n",
    "    assert shape[0] == size or shape[1] == size, 'found image {}, control {}'.format(shape, ctrl)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlPretrainModel:\n",
    "    # If session is not defined than default session will be used\n",
    "    def __init__(self, a3c_model, session, encoder):\n",
    "        self.word_repr = None\n",
    "        self.word_embeddings = None\n",
    "                \n",
    "        self.a3c_model = a3c_model\n",
    "        self.session = session \n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.device = '/cpu:0'\n",
    "        \n",
    "        self.build_graph()\n",
    "        \n",
    "        \n",
    "    def build_graph(self):\n",
    "        self.text_labels = tf.placeholder(tf.float32, shape=[None, 512], name=\"text_labels\")\n",
    "        self.actions_labels = tf.placeholder(tf.float32, \n",
    "                                  shape=[None, self.a3c_model.num_actions - 1], name=\"possible_labels\")\n",
    "        self.text_loss = tf.losses.mean_pairwise_squared_error(self.text_labels, self.a3c_model.text_pretrain)\n",
    "        self.actions_loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels = self.actions_labels, \n",
    "            logits = self.a3c_model.logits)\n",
    "        \n",
    "        self.actions_loss = tf.reduce_mean(self.actions_loss)\n",
    "        \n",
    "        self.lr = tf.placeholder_with_default(0.001, shape=(), name=\"lr\")\n",
    "        self.opt = tf.train.AdamOptimizer(self.lr)\n",
    "        \n",
    "        self.train_text_op = self.opt.minimize(self.text_loss)\n",
    "        self.train_actions_op = self.opt.minimize(self.actions_loss)\n",
    "        \n",
    "        \n",
    "    def read_imgs(self, batch):\n",
    "        imgs = []\n",
    "        \n",
    "        for ctrl in batch:\n",
    "            imgs.append(read_img(ctrl))\n",
    "            \n",
    "        return imgs\n",
    "    \n",
    "        \n",
    "    def to_(self, batch):\n",
    "        text_vectors = self.encoder.encode(batch)\n",
    "        \n",
    "    \n",
    "    def get_text_input(self, batch, imgs, lr, l2, dropout = 0.8):\n",
    "        text_vectors = self.encoder.encode(batch)\n",
    "        return {\n",
    "            self.a3c_model.img: imgs,\n",
    "            self.text_labels: text_vectors,\n",
    "            self.lr: lr,\n",
    "            self.a3c_model.l2: l2,\n",
    "            self.a3c_model.dropout: dropout\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def get_actions_input(self, batch, imgs, lr, l2, dropout = 0.8):\n",
    "        filtered_imgs = []\n",
    "        actions = []\n",
    "        for i, ctrl in enumerate(batch):\n",
    "            pa = ctrl['possible_actions']\n",
    "            if sum(pa) == 1:\n",
    "                filtered_imgs.append(imgs[i])\n",
    "                actions.append(pa)\n",
    "        \n",
    "        return {\n",
    "            self.a3c_model.img: filtered_imgs,\n",
    "            self.actions_labels: actions,\n",
    "            self.lr: lr,\n",
    "            self.a3c_model.l2: l2,\n",
    "            self.a3c_model.dropout: dropout\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def train(self, controls, epoch_start = 0, epoch_end = 5, \n",
    "              batch_size = 10, lr = 0.001, l2 = 0.001):\n",
    "        \n",
    "        for epoch in range(epoch_start, epoch_end):\n",
    "            total = len(controls)\n",
    "            random.shuffle(controls)\n",
    "            \n",
    "            print('epoch {} started, examples: {}'.format(epoch, total))\n",
    "            sum_text_loss = 0\n",
    "            sum_actions_loss = 0\n",
    "            processed = 0\n",
    "            batches = 0\n",
    "            for batch in split(controls, batch_size):\n",
    "                imgs = self.read_imgs(batch)\n",
    "                text_feed = self.get_text_input(batch, imgs, lr, l2)\n",
    "                _, text_loss = self.session.run([self.train_text_op, self.text_loss], \n",
    "                                                feed_dict = text_feed)\n",
    "                \n",
    "                actions_feed = self.get_actions_input(batch, imgs, lr, l2)\n",
    "                _, actions_loss = self.session.run([self.train_actions_op, self.actions_loss], \n",
    "                                                   feed_dict = actions_feed)\n",
    "                \n",
    "                processed += len(batch)\n",
    "                print ('Processed: {:2.2%}, text loss: {}, actions loss {}'\n",
    "                       .format(processed/total, text_loss, actions_loss) , end=\"\\r\")\n",
    "                \n",
    "                sum_text_loss += text_loss\n",
    "                sum_actions_loss += actions_loss\n",
    "                batches += 1\n",
    "            \n",
    "            print('epoch ended')\n",
    "            print('text loss: {}, actions loss: {}'\n",
    "                  .format(sum_text_loss / batches, sum_actions_loss / batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plyvel\n",
    "\n",
    "class CachedEncoder:\n",
    "    \n",
    "    # Cache all controls\n",
    "    def __init__(self, sentence_encoder, controls, session):\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.session = session\n",
    "        \n",
    "        self.db = plyvel.DB('sentence_embeddings.db', \n",
    "                            create_if_missing=True, \n",
    "                            write_buffer_size = 5*10**8, \n",
    "                            lru_cache_size = 10**8)\n",
    "        \n",
    "        self.init_cache(controls)\n",
    "        \n",
    "    def __enter__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __exit__(self):\n",
    "        self.db.close()\n",
    "        \n",
    "    \n",
    "    def to_bytes(self, str):\n",
    "        return str.encode(encoding='UTF-8')\n",
    "    \n",
    "    def from_bytes(self, b):\n",
    "        return b.decode(encoding='UTF-8')\n",
    "\n",
    "    \n",
    "    def get_text(self, source):\n",
    "        if source is None:\n",
    "            return None\n",
    "        \n",
    "        if isinstance(source, str):\n",
    "            text = source\n",
    "        elif 'label' not in source:\n",
    "            return None\n",
    "        else:\n",
    "            text = source['label']\n",
    "        \n",
    "        if not text:\n",
    "            return None\n",
    "\n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            return None\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def init_cache(self, controls):\n",
    "\n",
    "        texts = []\n",
    "        \n",
    "        for ctrl in controls:\n",
    "            text = self.get_text(ctrl)\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "        \n",
    "        texts = set(texts)\n",
    "        print('Going to add to cadhe {} texts: '.format(len(texts)))\n",
    "        \n",
    "        input_sentences = tf.placeholder(tf.string, shape=[None])\n",
    "        encode_op = self.sentence_encoder(input_sentences)\n",
    "\n",
    "        for batch in split(texts, 20):\n",
    "            embeddings = session.run(encode_op, feed_dict = {input_sentences: batch})\n",
    "            wb = self.db.write_batch()\n",
    "            for text, embedding in zip(batch, embeddings):\n",
    "                wb.put(self.to_bytes(text), embedding.tostring())\n",
    "            \n",
    "            wb.write()\n",
    "            del embeddings\n",
    "        \n",
    "        \n",
    "    def encode(self, controls):\n",
    "        result = []\n",
    "        for ctrl in controls:\n",
    "            text = self.get_text(ctrl)\n",
    "            assert text is not None\n",
    "                \n",
    "            key = self.to_bytes(text)\n",
    "            \n",
    "            b = self.db.get(key)\n",
    "            if b is None:\n",
    "                print('Not found vector for key: {}'.format(text))\n",
    "                \n",
    "            result.append(np.fromstring(b, dtype=np.float32))\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = []\n",
    "with open(dataset) as f:\n",
    "    for line in f:\n",
    "        ctrl = json.loads(line)\n",
    "        controls.append(ctrl)\n",
    "        \n",
    "to_train = [ctrl for ctrl in controls if ctrl['label'] and ctrl['label'].strip() != '']\n",
    "print('controls: {} to train: {}'.format(len(controls), len(to_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed = hub.Module(module_url)\n",
    "    \n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    encoder = CachedEncoder(embed, to_train, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "        corr,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "\n",
    "def run_and_plot(messages):\n",
    "    message_embeddings = encoder.encode(messages)\n",
    "    plot_similarity(messages, message_embeddings, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ctrl['label'] for ctrl in to_train[:10]]\n",
    "run_and_plot(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3c = A3CModel(len(Actions.actions), session = session, train_deep=True)\n",
    "model = ControlPretrainModel(a3c, session, encoder)\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    model.train(to_train, lr=0.001, \n",
    "            l2 = 0.001, \n",
    "            epoch_start = epoch, \n",
    "            epoch_end = epoch + 1, batch_size = 20)\n",
    "    \n",
    "    saver.save(session, './pretrain_checkpoint-{}'.format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
