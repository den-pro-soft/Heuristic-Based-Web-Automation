{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracing.selenium_utils.controls import *\n",
    "from abc import abstractmethod\n",
    "\n",
    "class IAction:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def apply(self, control, driver, user):\n",
    "        \"\"\"\n",
    "        Returns True or False if action was applied successfuly\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class InputBirthday(IAction):\n",
    "    @abstractmethod\n",
    "    def get_candidates(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def apply(self, ctrl, driver, user):\n",
    "        if ctrl.type not in [Types.text, Types.select]:\n",
    "            return False\n",
    "                \n",
    "        if ctrl.type == Types.text:\n",
    "            enter_text(driver, ctrl.elem, self.get_candidates()[0])\n",
    "        else:\n",
    "            val = None\n",
    "            for txt in self.get_candidates():\n",
    "                if txt in ctrl.values:\n",
    "                    val = txt\n",
    "                    \n",
    "            if val is None:\n",
    "                print('Not found values {} in control {}'.format(self.get_candidates(), ctrl))\n",
    "                return False\n",
    "            \n",
    "            select_combobox_value(driver, ctrl.elem, val)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "class InputBDay(InputBirthday):\n",
    "    def get_candidates(self):\n",
    "        return ['1', '01'] \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"InputBDay\"\n",
    "\n",
    "    \n",
    "class InputBMonth(InputBirthday):\n",
    "    def get_candidates(self):\n",
    "        return ['01', '1', 'January', 'Jan', 'january', 'jan']\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"InputBMonth\"\n",
    "\n",
    "    \n",
    "class InputBYear(InputBirthday):\n",
    "    def get_candidates(self):\n",
    "        return ['1972', '72']\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"InputBYear\"\n",
    "\n",
    "    \n",
    "class Click(IAction):\n",
    "    def apply(self, ctrl, driver, user):\n",
    "        if ctrl.type in [Types.radiobutton, Types.checkbox, Types.link, Types.button]:\n",
    "            click(driver, ctrl.elem)\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Click\"\n",
    "\n",
    "    \n",
    "class Wait(IAction):\n",
    "    def apply(self, ctrl, driver, user):\n",
    "        time.sleep(2)\n",
    "        return True\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Wait\"\n",
    "\n",
    "\n",
    "class Nothing(IAction):\n",
    "    def apply(self, ctrl, driver, user):\n",
    "        return True\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Do Nothing\"\n",
    "\n",
    "\n",
    "class Actions:\n",
    "    actions = [InputBDay(), InputBMonth(), InputBYear(), Click(), Wait(), Nothing()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "class A3CModel:\n",
    "    global_scope = \"global_model_scope\"\n",
    "    local_scope = \"local_model_scope\"\n",
    "    \n",
    "    def __init__(self, num_actions, global_model = None, session = None, name = None):\n",
    "        self.num_actions = num_actions\n",
    "        self.global_model = global_model\n",
    "        self.session = session\n",
    "        self.name = name or ''\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    @property\n",
    "    def is_global(self):\n",
    "        return self.global_model is None\n",
    "        \n",
    "    def build(self):\n",
    "        if self.session is None:\n",
    "            self.session = tf.Session()\n",
    "        \n",
    "        if self.is_global:\n",
    "            with tf.variable_scope(A3CModel.global_scope):\n",
    "                self.build_graph()\n",
    "                self.add_loss()\n",
    "                self.params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "                self.add_train_op()\n",
    "        else:\n",
    "            with tf.variable_scope(A3CModel.local_scope + self.name):\n",
    "                self.build_graph()\n",
    "                self.add_loss()\n",
    "                self.params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "                self.add_update_ops()\n",
    "\n",
    "    \n",
    "    def build_graph(self):\n",
    "        with tf.variable_scope('inputs') as sc:\n",
    "            # Batch x h x 612\n",
    "            self.img = tf.placeholder(tf.float32, (None, None, None, 4), \"img\")\n",
    "            self.dropout = tf.placeholder(tf.float32, (), \"dropout\")\n",
    "            \n",
    "            # Learning Rate\n",
    "            self.lr = tf.placeholder_with_default(0.1, (), 'lr')\n",
    "            \n",
    "            # Entropy Rate (use for regularization)\n",
    "            self.er = tf.placeholder_with_default(0.01, (), 'er')\n",
    "            \n",
    "            # Batch, Number of Action\n",
    "            self.performed_actions = tf.placeholder(tf.int32, (None), \"performed_actions\")\n",
    "            \n",
    "            # Batch\n",
    "            self.rewards = tf.placeholder(tf.float32, (None), 'rewards')\n",
    "\n",
    "        with tf.variable_scope('cnn') as sc:\n",
    "\n",
    "            end_points_collection = sc.original_name_scope + '_ep'\n",
    "\n",
    "            with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                                outputs_collections=[end_points_collection]):\n",
    "\n",
    "                # h/2, 306\n",
    "                net = slim.conv2d(self.img, 64, [5, 5], 2, padding='SAME',\n",
    "                                scope='conv1')\n",
    "\n",
    "                # h/4, 153\n",
    "                net = slim.conv2d(net, 64, [5, 5], 2, padding='SAME',\n",
    "                                scope='conv2')\n",
    "\n",
    "                # h/8, 76\n",
    "                net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "                net = slim.conv2d(net, 64, [5, 5], scope='conv3')\n",
    "\n",
    "                # h/16, 38\n",
    "                net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "                net = slim.conv2d(net, 64, [3, 3], scope='conv4')\n",
    "                net = slim.conv2d(net, 64, [3, 3], scope='conv5')\n",
    "                net = slim.conv2d(net, 64, [3, 3], scope='conv6')\n",
    "\n",
    "                # h/32, 18\n",
    "                net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            with slim.arg_scope([slim.conv2d],\n",
    "                                  weights_initializer=tf.truncated_normal_initializer(0.005),\n",
    "                                  biases_initializer=tf.constant_initializer(0.1)):\n",
    "\n",
    "                # h/32 - 3, 1\n",
    "                net = slim.avg_pool2d(net, [18, 18], padding='VALID',\n",
    "                                  scope='fc')\n",
    "                net = slim.dropout(net, self.dropout, scope='dropout')\n",
    "\n",
    "                # h/32 - 3, 1\n",
    "                net = slim.conv2d(net, 128, [1, 1], scope='fc2')\n",
    "\n",
    "                # Convert end_points_collection into a end_point dict.\n",
    "                end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "\n",
    "                # 128, Global Max Pooling\n",
    "                net = tf.reduce_max(net, [1, 2], keepdims=False, name='global_pool')\n",
    "                end_points['global_pool'] = net\n",
    "\n",
    "                # Policy\n",
    "                self.logits = slim.fully_connected(net, self.num_actions)\n",
    "\n",
    "                self.pi = tf.nn.softmax(self.logits)\n",
    "                self.v = slim.fully_connected(net, 1)\n",
    "\n",
    "        self.end_points = end_points\n",
    "        return net, end_points\n",
    "\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def add_loss(self):\n",
    "        # Advantage\n",
    "        advantage = self.rewards - self.v\n",
    "        value_loss = tf.nn.l2_loss(advantage)\n",
    "        \n",
    "        # Policy Loss: Log(pi) * advantage\n",
    "        policy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=self.performed_actions, logits=self.logits)\n",
    "        policy_loss *= tf.stop_gradient(advantage)\n",
    "        \n",
    "        # Entropy: H(pi)\n",
    "        entropy = -tf.reduce_sum(self.pi * tf.log(self.pi), axis=1, keepdims=True)  # encourage exploration\n",
    "        \n",
    "        # Summ Loss\n",
    "        self.loss = tf.reduce_mean(0.5 * value_loss + policy_loss - self.er * entropy)\n",
    "       \n",
    "        \n",
    "    def add_train_op(self):\n",
    "        self.opt = tf.train.AdamOptimizer()\n",
    "\n",
    "\n",
    "    def add_update_ops(self):\n",
    "        assert not self.is_global, \"Can't add pull and push operations to global model\"\n",
    "        assert self.global_model is not None, \"Global model must bet set\"\n",
    "        assert self.global_model.opt is not None, \"Global model must have optimizer .opt\"\n",
    "               \n",
    "        with tf.name_scope('update'):\n",
    "            # Gradients Computation\n",
    "            self.grads = [g for g in tf.gradients(self.loss, self.params) if g is not None]\n",
    "            \n",
    "            # Pull variables from global model\n",
    "            self.pull_global_op = [local_var.assign(global_var) for local_var, global_var in \n",
    "                            zip(self.params, global_model.params)]\n",
    "            \n",
    "            # Add gradients to global model variables\n",
    "            opt = self.global_model.opt\n",
    "            self.update_global_op = self.global_model.opt.apply_gradients(\n",
    "                zip(self.grads, self.global_model.params))\n",
    "            \n",
    "    \n",
    "    def update_global(self, feed_dict):\n",
    "        self.session.run([self.update_global_op], feed_dict)  \n",
    "        \n",
    "    def pull_global(self):\n",
    "        self.session.run([self.pull_global_op])\n",
    "\n",
    "    def get_action(self, image):\n",
    "        \"\"\"\n",
    "        Returns Action Id\n",
    "        \"\"\"\n",
    "        print('image shape:', image.shape)\n",
    "        pi = self.session.run(self.pi, feed_dict = {self.img: [image], self.dropout: 1.0})\n",
    "        print('got probabilities:', pi)\n",
    "        return np.random.choice(range(self.num_actions), p = pi[0])\n",
    "    \n",
    "    def train_from_memory(self, memory, dropout = 0.5, lr = 0.01, er = 0.01):\n",
    "        assert not self.is_global, \"Can't train Global Model\"\n",
    "        \n",
    "        # 1. Convert Memory to Input Batch\n",
    "        batch = memory.to_input()\n",
    "        batch_size = len(batch['img'])\n",
    "        print('batch_size: ', batch_size)\n",
    "        if batch_size <= 0:\n",
    "            return\n",
    "        \n",
    "        # 2. Create Feed Data\n",
    "        feed_data = {\n",
    "            self.img: batch['img'],\n",
    "            self.performed_actions: batch['actions'],\n",
    "            self.rewards: batch['rewards'],\n",
    "\n",
    "            self.dropout: dropout,\n",
    "            self.global_model.lr: lr,\n",
    "            self.er: er\n",
    "        }    \n",
    "        \n",
    "        # 3. Compute gradients and update global Model\n",
    "        self.update_global(feed_data)\n",
    "        \n",
    "        # 4. Copy Values from Global Model\n",
    "        self.pull_global()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import random\n",
    "import tracing.selenium_utils.controls as selenium_controls\n",
    "import tracing.selenium_utils.common as common\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "class IRewardsCalculator:\n",
    "    \n",
    "    def start(self):\n",
    "        pass\n",
    "    \n",
    "    def before_action(self, driver, action):\n",
    "        pass\n",
    "    \n",
    "    def after_action(self, driver, action):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def is_final(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    @abstractmethod\n",
    "    def calc_reward(self, is_success):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def calc_final_reward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class PopupRewardsCalculator(IRewardsCalculator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.is_final_state = False\n",
    "    \n",
    "    def start(self):\n",
    "        self.is_final_state = False\n",
    "    \n",
    "    def is_displayed(self, elem):\n",
    "        try:\n",
    "            # Check that location is accessible\n",
    "            tmp = elem.location\n",
    "            # Check selenium method is_displayed and that height > 1 and width > 1\n",
    "            return elem.is_displayed() and elem.size['width'] > 1 and elem.size['height'] > 1\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def extract_random_controls(self, driver, max_num = 10):\n",
    "        selects = selenium_controls.get_selects(driver)\n",
    "        inputs = selenium_controls.get_inputs(driver)\n",
    "        buttons = selenium_controls.get_buttons(driver)\n",
    "        links = selenium_controls.get_links(driver)\n",
    "\n",
    "        checkboxes = selenium_controls.get_checkboxes(driver)\n",
    "        radios = selenium_controls.get_radiobuttons(driver)\n",
    "        \n",
    "        controls = selects + inputs + buttons + links + checkboxes + radios\n",
    "        visible = [ctrl for ctrl in controls if self.is_displayed(ctrl)]\n",
    "        \n",
    "        if len(visible) < max_num:\n",
    "            return visible\n",
    "        \n",
    "        return random.sample(visible, max_num)\n",
    "    \n",
    "    def is_popup_exists(self, driver):\n",
    "        # 1. Scroll to Top\n",
    "        common.scroll_to_top(driver)\n",
    "\n",
    "        # 2. Extract visible controls\n",
    "        controls = self.extract_random_controls(driver, 10)\n",
    "        \n",
    "        # 3. Check how many elements are hidden by other elements\n",
    "        covered = 0\n",
    "        for ctrl in controls:\n",
    "            if not selenium_controls.is_visible(ctrl):\n",
    "                covered += 1\n",
    "        \n",
    "        print('controls: {}, covered: {}'.format(len(controls), covered))\n",
    "        return covered >= 3\n",
    "    \n",
    "    def get_domain(self, url):\n",
    "        return urlparse(url).netloc\n",
    "    \n",
    "    def is_final(self):\n",
    "        return self.is_final_state\n",
    "    \n",
    "    def before_action(self, driver, action):\n",
    "        self.had_popup = self.is_popup_exists(driver)\n",
    "        self.url = self.get_domain(driver.current_url)\n",
    "        \n",
    "    def after_action(self, driver, action):\n",
    "        self.have_popup = self.is_popup_exists(driver)\n",
    "        self.new_url = self.get_domain(driver.current_url)\n",
    "        self.is_final_state = self.new_url != self.url or not self.have_popup\n",
    "    \n",
    "    def calc_reward(self, is_success):\n",
    "        if self.new_url != self.url:\n",
    "            return -100\n",
    "        elif self.had_popup and not self.have_popup:\n",
    "            return 100\n",
    "        elif not is_success:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def calc_final_reward(self):\n",
    "        if not self.have_popup:\n",
    "            return 0\n",
    "        else:\n",
    "            # Haven't close popup\n",
    "            return -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tracing.selenium_utils.common as common\n",
    "import tracing.selenium_utils.controls as selenium_controls\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import os\n",
    "import numpy as np\n",
    "import traceback\n",
    "import time\n",
    "    \n",
    "\n",
    "class Environment:\n",
    "    \n",
    "    def __init__(self, rewards, user, width = 612, headless = True):\n",
    "        self.rewards = rewards\n",
    "        self.user = user\n",
    "        self.width = width\n",
    "        self.headless = headless\n",
    "        self.step = 0\n",
    "        self.driver = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        if not self.driver:\n",
    "            self.driver = common.create_chrome_driver(headless = self.headless)\n",
    "\n",
    "    def is_final(self):        \n",
    "        return self.rewards.is_final()\n",
    "    \n",
    "    def start(self, url):\n",
    "        if not self.driver:\n",
    "            self.driver = create_chrome_driver(headless = self.headless)\n",
    "\n",
    "        if not url.startswith('http://') and not url.startswith('https://'):\n",
    "            url = 'http://' + url\n",
    "        \n",
    "        self.driver.get(url)\n",
    "        self.rewards.start()\n",
    "        self.step = 0\n",
    "        \n",
    "        time.sleep(5)\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print(\"exit is called\")\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "\n",
    "    # Returns 3D Numpy array of image representation\n",
    "    # Channels x Width X Height\n",
    "    def get_screenshot_as_array(self):\n",
    "        assert self.driver is not None\n",
    "        \n",
    "        # 1. Create temp file\n",
    "        _, tmp = tempfile.mkstemp(suffix='.png')\n",
    "\n",
    "        # 2. Take a screenshot\n",
    "        scale = common.get_scale(self.driver)    \n",
    "        common.get_full_page_screenshot(self.driver, tmp, scale)    \n",
    "\n",
    "        # 3. Resize image\n",
    "        img = Image.open(tmp)\n",
    "        width_scale = (self.width / float(img.size[0]))\n",
    "        height = int((float(img.size[1]) * float(width_scale)))\n",
    "        img = img.resize((self.width, height), Image.ANTIALIAS)\n",
    "        img.save(tmp)\n",
    "\n",
    "        # 4. Read as a numpy array\n",
    "        image = misc.imread(tmp)\n",
    "        os.remove(tmp)\n",
    "\n",
    "        [h, w, _] = image.shape\n",
    "        if h < w:\n",
    "            to_add = np.ndarray([w-h, w, 3], dtype=float)\n",
    "            to_add.fill(0)\n",
    "            image = np.append(image, to_add, axis=0)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    # Returns input images for different controls\n",
    "    def get_controls_as_input(self):\n",
    "        \n",
    "        source_image = self.get_screenshot_as_array()\n",
    "            \n",
    "        image = (source_image - 128.0) / 128.0\n",
    "        scroll_to_top(self.driver)\n",
    "        \n",
    "        controls_info = selenium_controls.extract_controls(self.driver)\n",
    "        result = []\n",
    "        \n",
    "        scroll_to_top(self.driver)\n",
    "        \n",
    "        for ctrl in controls_info:\n",
    "            [h, w, _] = image.shape\n",
    "            mask = np.ndarray([h, w, 1], dtype=float)\n",
    "            mask.fill(0)\n",
    "            top = ctrl.location['y']\n",
    "            left = ctrl.location['x']\n",
    "            bottom = top + ctrl.size['height']\n",
    "            right = left + ctrl.size['width']\n",
    "\n",
    "            mask[top:bottom, left:right, 0] = 1\n",
    "            array = np.append(image, mask, axis=-1)\n",
    "            result.append((ctrl, array))\n",
    "\n",
    "        # Sort by Top then by Left of control location\n",
    "        result.sort(key = lambda pair: (pair[0].location['y'], pair[0].location['x']))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def apply_action(self, control, action):\n",
    "        success = False\n",
    "        try:\n",
    "            self.rewards.before_action(self.driver, action)\n",
    "            self.step += 1\n",
    "            success = action.apply(control, self.driver, self.user)\n",
    "        except:\n",
    "            success = False\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            self.rewards.after_action(self.driver, action)\n",
    "            \n",
    "        return self.rewards.calc_reward(success)\n",
    "    \n",
    "    def calc_final_reward(self):\n",
    "        return self.rewards.calc_final_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = Environment()\n",
    "# controls = env.get_controls_as_input(driver)\n",
    "# for control, array in controls:\n",
    "#     print(control)\n",
    "#     print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popup_urls = [\n",
    "    # Choose from two options popups\n",
    "    'monstervape.com',\n",
    "    'twistedcigs.com',\n",
    "    'ecigsejuice.com',\n",
    "    'vape-fuel.com',\n",
    "    'powervapes.net',\n",
    "    'ecigexpress.com',\n",
    "    'ecigvaporstore.com',\n",
    "    \n",
    "    # Subscribe\n",
    "    'cigarmanor.com',\n",
    "    \n",
    "    # Enter date popups\n",
    "    'thecigarshop.com',\n",
    "    'cigartowns.com',\n",
    "    'docssmokeshop.com',\n",
    "    'enhancedecigs.com',\n",
    "    'betamorphecigs.com',\n",
    "    \n",
    "    # Accept Cookie\n",
    "    'theglamourshop.com'\n",
    "]\n",
    "\n",
    "no_popup_urls = [\n",
    "    'dixieems.com',\n",
    "    'firstfitness.com',\n",
    "    'sandlakedermatology.com',\n",
    "    'dixieems.com',\n",
    "    'anabolicwarfare.com',\n",
    "    'jonessurgical.com',\n",
    "    'srandd.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import random\n",
    "\n",
    "class ActionsMemory:\n",
    "    def __init__(self, gamma):\n",
    "        self.imgs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def append(self, img, action, reward):\n",
    "        self.imgs.append(img)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "    \n",
    "    def to_input(self):\n",
    "        \n",
    "        sum_reward = 0\n",
    "        rewards = []\n",
    "        for i in range(len(self.imgs) - 1, -1, -1):\n",
    "            sum_reward *= self.gamma\n",
    "            sum_reward += self.rewards[i]\n",
    "            rewards.append(sum_reward)\n",
    "        \n",
    "        return {\n",
    "            \"img\": self.imgs,\n",
    "            \"actions\": self.actions,\n",
    "            \"rewards\": rewards\n",
    "            }\n",
    "        \n",
    "\n",
    "class ActorLearnerWorker(threading.Thread):\n",
    "    global_step = 0\n",
    "    avg_reward = 0\n",
    "    step_rewards = []\n",
    "    \n",
    "    def __init__(self, name, urls, global_model, env, max_steps = 1000):\n",
    "        threading.Thread.__init__(self)\n",
    "        \n",
    "        self.name = name\n",
    "        self.urls = urls\n",
    "        self.session = global_model.session\n",
    "        self.global_model = global_model\n",
    "        self.local_model = A3CModel(global_model.num_actions, global_model = global_model, \n",
    "                                    session = self.session, name = self.name)\n",
    "        self.env = env\n",
    "        self.max_steps = max_steps\n",
    "    \n",
    "    def get_url(self):\n",
    "        return random.choice(self.urls)\n",
    "    \n",
    "    def run(self):\n",
    "        n_step = 5\n",
    "        gamma = 0.99\n",
    "        lr = 0.01\n",
    "        entropy_l = 0.01\n",
    "        \n",
    "        with self.env:\n",
    "            while ActorLearnerWorker.global_step < self.max_steps:\n",
    "                ActorLearnerWorker.global_step += 1\n",
    "                url = self.get_url()\n",
    "\n",
    "                print('\\n\\nstarted url', 'http://' + url)\n",
    "                self.env.start(url)\n",
    "\n",
    "                controls = self.env.get_controls_as_input()\n",
    "                print('extracted controls:', len(controls))\n",
    "                # Popups specific, don't update window\n",
    "                c_idx = 0\n",
    "                sum_reward = 0\n",
    "\n",
    "                while True:\n",
    "                    memory = ActionsMemory(gamma = gamma)\n",
    "                    # ToDo 1. Neat working with controls\n",
    "                    # ToDo 2. Add scrolling?\n",
    "                    while not self.env.is_final() and c_idx < len(controls):\n",
    "                        ctrl, inp = controls[c_idx]\n",
    "                        print('control:', ctrl)\n",
    "                        action_id = self.local_model.get_action(inp)\n",
    "                        action = Actions.actions[action_id]\n",
    "                        print('got action:', action)\n",
    "                        \n",
    "                        reward = self.env.apply_action(ctrl, action)\n",
    "                        print('reward:', reward)\n",
    "\n",
    "                        memory.append(inp, action_id, reward)\n",
    "\n",
    "                        c_idx += 1\n",
    "                        sum_reward += reward * (gamma ** self.env.step)\n",
    "                        \n",
    "                        if (self.env.step + 1) % n_step == 0:\n",
    "                            break\n",
    "\n",
    "                    self.local_model.train_from_memory(memory, dropout = 1.0 , lr = lr, er = entropy_l)\n",
    "\n",
    "                    if self.env.is_final() or c_idx >= len(controls):\n",
    "                        sum_reward += self.env.calc_final_reward() * (gamma ** self.env.step)\n",
    "                        ActorLearnerWorker.avg_reward = ActorLearnerWorker.avg_reward * 0.99 + 0.01 * sum_reward\n",
    "                        ActorLearnerWorker.step_rewards.append(sum_reward)\n",
    "                        print(sum_reward)\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "session = tf.Session()\n",
    "\n",
    "num_workers = 1\n",
    "\n",
    "global_model = A3CModel(len(Actions.actions), session = session)\n",
    "workers = []\n",
    "\n",
    "for i in range(num_workers):\n",
    "    env = Environment(PopupRewardsCalculator(), user={}, headless=True)\n",
    "    workers.append(ActorLearnerWorker(\"worker-{}\".format(i), popup_urls, global_model, env, 1000))\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "worker_threads = []\n",
    "for worker in workers:\n",
    "    worker.start()\n",
    "\n",
    "coord.join(workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Environment\n",
    "from tracing.selenium_utils.common import *\n",
    "\n",
    "env = Environment(PopupRewardsCalculator(), user={}, headless=False)\n",
    "\n",
    "with env:\n",
    "    env.start('enhancedecigs.com')\n",
    "    env.driver.set_script_timeout(100)\n",
    "\n",
    "    ctrls = env.get_controls_as_input()\n",
    "    assert len(ctrls) == 6\n",
    "    for ctrl in ctrls:\n",
    "        print(ctrl[0])\n",
    "\n",
    "    dayCtrl = ctrls[0][0]\n",
    "    monthCtrl = ctrls[1][0]\n",
    "    yearCtrl = ctrls[2][0]\n",
    "    check = ctrls[3][0]\n",
    "    enter = ctrls[5][0]\n",
    "\n",
    "    assert env.apply_action(dayCtrl, InputBDay()) == 0\n",
    "    assert env.apply_action(monthCtrl, InputBMonth()) == 0\n",
    "    assert env.apply_action(yearCtrl, InputBYear()) == 0\n",
    "    assert env.apply_action(check, Click()) == 0\n",
    "    assert env.apply_action(enter, Click()) == 100\n",
    "\n",
    "    assert env.calc_final_reward() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Popups Detecting\n",
    "\n",
    "import time\n",
    "\n",
    "rewards = PopupRewardsCalculator()\n",
    "\n",
    "driver = create_chrome_driver()\n",
    "\n",
    "for url in no_popup_urls:\n",
    "    print('url: ', url)\n",
    "    driver.get('http://' + url)\n",
    "    time.sleep(2)\n",
    "    assert not rewards.is_popup_exists(driver)\n",
    "\n",
    "for url in popup_urls:\n",
    "    print('url: ', url)\n",
    "    driver.get('http://' + url)\n",
    "    time.sleep(2)\n",
    "    assert rewards.is_popup_exists(driver)\n",
    "\n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rewards = ActorLearnerWorker.step_rewards\n",
    "plt.plot(np.arange(len(rewards)), rewards)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Total moving reward')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
